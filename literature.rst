1. Zeiler, M. D., Krishnan, D., Taylor, G. W. & Fergus, R. Deconvolutional Networks. at <http://www.matthewzeiler.com/wp-content/uploads/2017/07/cvpr2010.pdf>
2. Bach, S. et al. On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation. PLoS One 10, e0130140 (2015).
3. Selvaraju, R. R. et al. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. at <http://gradcam.cloudcv.org>
4. Erhan Dumitru, Bengio Yoshua, Courville Aaron, V. P. Visualizing Higher-Layer Features of a Deep Network. at <https://www.researchgate.net/profile/Aaron_Courville/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network/links/53ff82b00cf24c81027da530.pdf>
5. Sundararajan, M., Taly, A. & Yan, Q. Axiomatic Attribution for Deep Networks. at <https://arxiv.org/pdf/1703.01365.pdf>
6. Smilkov, D. et al. Embedding Projector: Interactive Visualization and Interpretation of Embeddings. at <https://arxiv.org/pdf/1611.05469.pdf>
7. Van Der Maaten, L. & Hinton, G. Visualizing Data using t-SNE. J. Mach. Learn. Res. 9, 2579â€“2605 (2008).
8. Szegedy, C. et al. Intriguing properties of neural networks. at <https://arxiv.org/pdf/1312.6199.pdf?not-changed>
9. Goodfellow, I. J., Shlens, J. & Szegedy, C. EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES. at <https://arxiv.org/pdf/1412.6572.pdf>
10. Nguyen, A., Yosinski, J. & Clune, J. Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images. at <http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.pdf>
11. Dosovitskiy, A. & Brox, T. Inverting Convolutional Networks with Convolutional Networks. at <https://pdfs.semanticscholar.org/993c/55eef970c6a11ec367dbb1bf1f0c1d5d72a6.pdf>
12. Mahendran, A. & Vedaldi, A. Understanding Deep Image Representations by Inverting Them. at <http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf>
13. Nguyen, A. et al. Synthesizing the preferred inputs for neurons in neural networks via deep generator networks. at <http://papers.nips.cc/paper/6519-synthesizing-the-preferred-inputs-for-neurons-in-neural-networks-via-deep-generator-networks.pdf>
14. Nguyen, A., Yosinski, J. & Clune, J. Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks. at <https://pdfs.semanticscholar.org/e184/6e3e95f5cec862e9b6f812e426908fcb46c7.pdf>
15. Yosinski, J., Clune, J., Nguyen, A., Fuchs, T. & Lipson, H. Understanding Neural Networks Through Deep Visualization. (2015). at <https://arxiv.org/pdf/1506.06579.pdf>
16. Springenberg, J. T., Dosovitskiy, A., Brox, T. & Riedmiller, M. STRIVING FOR SIMPLICITY: THE ALL CONVOLUTIONAL NET. at <https://arxiv.org/pdf/1412.6806.pdf (http://arxiv.org/pdf/1412.6806.pdf)>
17. Simonyan, K., Vedaldi, A. & Zisserman, A. Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. at <https://arxiv.org/pdf/1312.6034.pdf>
18. Shi, S., Wang, Q., Xu, P. & Chu, X. Benchmarking State-of-the-Art Deep Learning Software Tools. at <https://arxiv.org/pdf/1608.07249v7.pdf>
19. Zeiler, M. D. & Fergus, R. Visualizing and Understanding Convolutional Networks. (2013). at <http://arxiv.org/abs/1311.2901>
20. Szegedy, C. et al. Intriguing properties of neural networks. (2013). at <http://arxiv.org/abs/1312.6199>
21. Girshick, R., Donahue, J., Darrell, T. & Malik, J. Rich feature hierarchies for accurate object detection and semantic segmentation. (2013). at <http://arxiv.org/abs/1311.2524>
