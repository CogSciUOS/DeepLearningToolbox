{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with PyTorch\n",
    "\n",
    "Based on the [code](https://github.com/pytorch/examples/tree/master/mnist) from [PyTorch / examples](https://github.com/pytorch/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: False\n"
     ]
    }
   ],
   "source": [
    "# input batch size for training (default: 64)\n",
    "batch_size = 64\n",
    "\n",
    "# input batch size for testing (default: 1000)\n",
    "test_batch_size = 1000\n",
    "\n",
    "# number of epochs to train (default: 10)\n",
    "epochs = 10\n",
    "\n",
    "# learning rate (default: 0.01)\n",
    "lr = 0.01\n",
    "\n",
    "# SGD momentum (default: 0.5)\n",
    "momentum = 0.5\n",
    "\n",
    "# disables CUDA training\n",
    "no_cuda = True\n",
    "\n",
    "# random seed (default: 1)\n",
    "seed = 1\n",
    "\n",
    "# how many batches to wait before logging training status\n",
    "log_interval = 10\n",
    "\n",
    "# Setting seed for reproducibility.\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "print(\"CUDA: {}\".format(cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudakwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # Precalcualted values.\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=mnist_transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_set = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=mnist_transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    **cudakwargs\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    **cudakwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulate training and testing in functions\n",
    "\n",
    "The function `train` implements one epoch of training. It will loop through the training data, fetching training batches and computing the model output. The predicted output is compared to the target output using the negative log likelihood function `torch.nn.functional.nll_loss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, epoch, log_interval=100):\n",
    "    model.train() # Set model to training mode.\n",
    "    for batch_idx, (data, target) in enumerate(loader): # Getting the next batch.\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target) \n",
    "        optimizer.zero_grad() # Setting gradients to zero, to avoid accumulation.\n",
    "        output = model.forward(data) # Passing data through the network.\n",
    "        loss = F.nll_loss(output, target) # Calculating the loss.\n",
    "        loss.backward() # Compute gradients.\n",
    "        optimizer.step() # Update weights.\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the test procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(loader) # loss function already averages over batch size\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(loader.dataset),\n",
    "        100. * correct / len(loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Module API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2d_2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.dense_1 = nn.Linear(3872, 64)\n",
    "        self.dense_2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv2d_1(x), kernel_size=2))\n",
    "        x = F.relu(self.conv2d_2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = x.view(-1, 3872)\n",
    "        x = F.relu(self.dense_1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.dense_2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the model\n",
    "\n",
    "The model is created by instantiating the model class. Notice that we have to explicitly activate CUDA for the model if we want it to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 3872])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307804\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.821783\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.844431\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.607474\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.433042\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.457261\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.405718\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.417186\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.270134\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.280051\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.435494\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.199564\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.255928\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.269778\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.120274\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.283706\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.161244\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.110074\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.260236\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.056930\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "for epoch in range(1, 3):\n",
    "    train(model, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0856, Accuracy: 9732/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential API (http://pytorch.org/docs/master/nn.html#torch.nn.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "model_seq = nn.Sequential(OrderedDict([\n",
    "    ('conv2d_1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)),\n",
    "    ('relu_1', nn.ReLU()),\n",
    "    ('max_pooling2d_1', nn.MaxPool2d(kernel_size=2)),\n",
    "    ('conv2d_2', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)),\n",
    "    ('relu_2', nn.ReLU()),\n",
    "    ('dropout_1', nn.Dropout(p=0.25)),\n",
    "    ('flatten_1', Flatten()),\n",
    "    ('dense_1', nn.Linear(3872, 64)),\n",
    "    ('relu_3', nn.ReLU()),\n",
    "    ('dropout_2', nn.Dropout(p=0.5)),\n",
    "    ('dense_2', nn.Linear(64, 10)),\n",
    "    ('readout', nn.LogSoftmax())\n",
    "]))\n",
    "\n",
    "if cuda:\n",
    "    model_seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.__call__ of Net (\n",
       "  (conv2d_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2d_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dense_1): Linear (3872 -> 64)\n",
       "  (dense_2): Linear (64 -> 10)\n",
       ")>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Net.forward of Net (\n",
       "  (conv2d_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2d_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dense_1): Linear (3872 -> 64)\n",
       "  (dense_2): Linear (64 -> 10)\n",
       ")>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 3872])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model_seq.parameters():\n",
    "    print(p.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (conv2d_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu_1): ReLU ()\n",
      "  (max_pooling2d_1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (conv2d_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu_2): ReLU ()\n",
      "  (dropout_1): Dropout (p = 0.25)\n",
      "  (flatten_1): Flatten (\n",
      "  )\n",
      "  (dense_1): Linear (3872 -> 64)\n",
      "  (relu_3): ReLU ()\n",
      "  (dropout_2): Dropout (p = 0.5)\n",
      "  (dense_2): Linear (64 -> 10)\n",
      "  (readout): LogSoftmax ()\n",
      ")\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "ReLU ()\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "ReLU ()\n",
      "Dropout (p = 0.25)\n",
      "Flatten (\n",
      ")\n",
      "Linear (3872 -> 64)\n",
      "ReLU ()\n",
      "Dropout (p = 0.5)\n",
      "Linear (64 -> 10)\n",
      "LogSoftmax ()\n"
     ]
    }
   ],
   "source": [
    "for m in model_seq.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "ReLU ()\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "ReLU ()\n",
      "Dropout (p = 0.25)\n",
      "Flatten (\n",
      ")\n",
      "Linear (3872 -> 64)\n",
      "ReLU ()\n",
      "Dropout (p = 0.5)\n",
      "Linear (64 -> 10)\n",
      "LogSoftmax ()\n"
     ]
    }
   ],
   "source": [
    "for m in model_seq.children():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of Sequential (\n",
       "  (conv2d_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_1): ReLU ()\n",
       "  (max_pooling2d_1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv2d_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu_2): ReLU ()\n",
       "  (dropout_1): Dropout (p = 0.25)\n",
       "  (flatten_1): Flatten (\n",
       "  )\n",
       "  (dense_1): Linear (3872 -> 64)\n",
       "  (relu_3): ReLU ()\n",
       "  (dropout_2): Dropout (p = 0.5)\n",
       "  (dense_2): Linear (64 -> 10)\n",
       "  (readout): LogSoftmax ()\n",
       ")>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "ReLU ()\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "ReLU ()\n",
      "Dropout (p = 0.25)\n",
      "Flatten (\n",
      ")\n",
      "Linear (3872 -> 64)\n",
      "ReLU ()\n",
      "Dropout (p = 0.5)\n",
      "Linear (64 -> 10)\n",
      "LogSoftmax ()\n"
     ]
    }
   ],
   "source": [
    "for l in model_seq:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv2d_1', Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))),\n",
       "             ('relu_1', ReLU ()),\n",
       "             ('max_pooling2d_1',\n",
       "              MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))),\n",
       "             ('conv2d_2', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))),\n",
       "             ('relu_2', ReLU ()),\n",
       "             ('dropout_1', Dropout (p = 0.25)),\n",
       "             ('flatten_1', Flatten (\n",
       "              )),\n",
       "             ('dense_1', Linear (3872 -> 64)),\n",
       "             ('relu_3', ReLU ()),\n",
       "             ('dropout_2', Dropout (p = 0.5)),\n",
       "             ('dense_2', Linear (64 -> 10)),\n",
       "             ('readout', LogSoftmax ())])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model_seq.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.320623\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.501908\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.895033\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.508193\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.546440\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.461239\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.339877\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.372804\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.633542\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.338278\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.258300\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.240900\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.247753\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.171940\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.391493\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.212401\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.193295\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.310381\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.316394\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.275944\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    train(model_seq, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1460, Accuracy: 9571/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model_seq, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading the model\n",
    "\n",
    "There are two methods provided by\n",
    "* Saving model parameters\n",
    "* Saving the entire model (may be less stable to changes)\n",
    "\n",
    "References:\n",
    "\n",
    "* [PyTorch: Serialization semantics](http://pytorch.org/docs/notes/serialization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = 'example_torch_mnist_model'\n",
    "if cuda: model_file += '_gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: saving the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = model_file + '.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_seq.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Net()\n",
    "if cuda:\n",
    "    model2.cuda()\n",
    "model2.load_state_dict(torch.load(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0856, Accuracy: 9732/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model2, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: saving the entire model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = model_file + '.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/miniconda/envs/dnnviz/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.save(model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = torch.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0856, Accuracy: 9732/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model3, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
